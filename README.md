Debe realizar un fork de este repositorio para desarrollar y entregar su trabajo.  

---

## Ejercicio Practico para Dataops

Este reto tiene como objetivo evaluar la capacidad para dise√±ar e implementar un **ciclo completo de datos** que asegure:

1. **Calidad del software**, reflejada en la implementaci√≥n de scripts robustos y probados para la gesti√≥n de metadatos.  
2. **Calidad y gobierno de datos**, con validaciones autom√°ticas en dbt y registro de resultados en un cat√°logo central.  
3. **Trazabilidad completa**, desde la fuente hasta los indicadores finales, con **Dataplex** como punto de observabilidad.  
4. **Orquestaci√≥n y control de calidad continua**, mediante pr√°cticas de CI/CD orientadas a DataOps.

---

## üóÇÔ∏è Dataset y dominio del caso

El caso se basa en datos p√∫blicos de Google BigQuery:  
**`bigquery-public-data.thelook_ecommerce`**

Estas tablas simulan la operaci√≥n de una tienda en l√≠nea y permiten modelar clientes, productos y ventas.  
El flujo debe cubrir desde la ingesta hasta la visualizaci√≥n anal√≠tica.

Tablas base:  
- `orders`  
- `order_items`  
- `users`  
- `products`

---

## üß± Capa Staging

La capa **staging** tiene como finalidad limpiar, estandarizar y preparar los datos para su an√°lisis.  

### Requisitos:
- Estandarizar nombres y tipos de columnas.  
- Convertir fechas a formato `TIMESTAMP` y valores num√©ricos a `NUMERIC`.  
- Eliminar duplicados.  
- Validar relaciones referenciales entre tablas:
  - Cada orden debe tener un cliente (`user_id` en `users`).  
  - Cada art√≠culo debe corresponder a un producto (`product_id` en `products`).  
  - Cada orden de `order_items` debe existir en `orders`.  

### Resultados esperados:
- Datos coherentes, limpios y con tipos consistentes.  
- Reporte de calidad de datos documentando:
  - Registros v√°lidos y errores detectados.  
  - Relaciones validadas y resultados de integridad.  
  - Estado general de los **tests de dbt** para cada modelo de staging.

---

## üèóÔ∏è Capa Mart

La capa **mart** consolida la informaci√≥n para el an√°lisis de negocio.

### Modelos requeridos:
- `dim_customer`: cat√°logo √∫nico de clientes con pa√≠s, g√©nero y fecha de registro.  
- `dim_product`: cat√°logo de productos con categor√≠a y precios promedio.  
- `fact_order_items`: detalle de ventas, uniendo √≥rdenes, art√≠culos y productos.  
- `fct_daily_sales`: resumen diario de ventas y comportamiento del cliente.

### M√©tricas principales:
| Indicador | Definici√≥n |
|------------|------------|
| **Item Revenue** | Cantidad √ó Precio unitario |
| **Total Revenue** | Suma de ingresos diarios |
| **Orders Count** | Total de √≥rdenes √∫nicas |
| **Average Order Value (AOV)** | Revenue total √∑ N√∫mero de √≥rdenes |
| **Revenue por Pa√≠s** | Ingreso agrupado por pa√≠s |
| **Distribuci√≥n por G√©nero** | Porcentaje de ventas por g√©nero del cliente |

### Pruebas esperadas:
- not_null sobre order_id (todas las √≥rdenes deben tener identificador).
- unique sobre order_id en stg_orders (no debe repetirse).
- relationships entre stg_order_items.order_id y stg_orders.order_id (cada art√≠culo pertenece a una orden).
- accepted_values sobre stg_orders.status con valores v√°lidos: 'Complete', 'Cancelled', 'Returned'.
- Verificar que`item_revenue = quantity * sale_price`.  
- Evaluaci√≥n y documentaci√≥n del resultado de los tests:  
  - Identificar modelos con fallas o reglas incumplidas.
	- Describir el tipo de error (integridad, dominio o negocio).
	- Registrar el porcentaje global de cumplimiento (Data Quality Score) como parte de los metadatos del modelo.

---

## üóÉÔ∏è Gobierno y Metadatos (Dataplex)

La capa de **gobierno** debe centralizar la informaci√≥n t√©cnica y de negocio de todo el flujo de datos.

### Requisitos:
- Publicar en Dataplex, si no se cuenta con acceso a Dataplex, podr√° entregar los metadatos en formato JSON/YAML:
  - Modelos de la capa staging y mart.  
  - Estado de los **tests de dbt** .  
- Incluir metadatos clave:
  - Propietario, dominio, sensibilidad, dataset y fuente original.  
  - √öltima actualizaci√≥n (`last_update`) y estado del test dbt (`passed`, `failed`).  
  - Puntaje de calidad global (DQ Score).  
- Representar relaciones:
  - Fuente ‚Üí Staging ‚Üí Mart ‚Üí Sem√°ntica ‚Üí Dashboard.  

El objetivo es que **Dataplex refleje visualmente la trazabilidad completa**, permitiendo observar:
- Qu√© modelos tienen relacion o dependencia.  
- Qu√© tests de dbt est√°n asociados y cu√°l fue su resultado.  
- Qu√© equipos o personas son responsables de cada objeto.

---

## üíª Calidad del Software

El reto incluye la evaluaci√≥n de la calidad **exclusivo para scripts de metadatos** desarrollados para alimentar Dataplex.

### Aspectos a evaluar:
- **Estructura modular:** el c√≥digo debe estar separado en m√≥dulos para lectura, procesamiento y publicaci√≥n de metadatos.  
- **Pruebas unitarias:** todos los componentes deben contar con pruebas que validen el comportamiento esperado.  
- **Cobertura m√≠nima:** se espera una cobertura de pruebas **superior al 85 %** en el m√≥dulo de metadatos.  
- **Linting y convenciones:** se aplican normas PEP8 y herramientas de validaci√≥n de estilo.  
- **Idempotencia:** las ejecuciones repetidas no deben duplicar ni alterar datos existentes.  
- **Errores controlados:** los fallos deben ser manejados con mensajes claros y no interrumpir la ejecuci√≥n total del flujo.

---

## üîÅ CI/CD orientado a DataOps

1) Pipeline de Software (m√≥dulo de metadatos)
	‚Ä¢	Alcance: c√≥digo de metadata_loader (parsers, normalizadores, publicadores a Dataplex).  
  ‚Ä¢	Linting & estilo: cumplimiento de convenciones (PEP8/estilo definido).  
  ‚Ä¢	Pruebas unitarias: cobertura m√≠nima ‚â• 85% del m√≥dulo.  
  ‚Ä¢	Contratos de entrada/salida: validaci√≥n estructural de metadatos (entries, lineage, estados de tests).  
  ‚Ä¢	Idempotencia b√°sica: dos ejecuciones consecutivas con la misma entrada producen la misma salida (sin duplicados).  
  ‚Ä¢	Artefactos esperados: reporte de pruebas, reporte de cobertura y resumen de metadatos validados.  
  ‚Ä¢	Criterio de aprobaci√≥n (gate): el pipeline falla si la cobertura est√° por debajo del umbral, si hay pruebas unitarias fallidas o si la validaci√≥n de contratos de metadatos no es satisfactoria.  

2) Pipeline de Datos (dbt)
	‚Ä¢	Alcance: modelos stg_*, dim_*, fact_*, fct_* y sus tests de datos en dbt.
	‚Ä¢	Pruebas de datos: not_null, unique, relationships, accepted_values y pruebas de negocio (p. ej., item_revenue = quantity * sale_price).
	‚Ä¢	Contratos y documentaci√≥n: tipos, descripciones y ownership declarados en schema.yml.
	‚Ä¢	Publicaci√≥n de calidad: registrar como metadatos el estado de cada test (passed/failed), porcentaje de cumplimiento (Data Quality Score) y √∫ltima ejecuci√≥n.
	‚Ä¢	Criterio de aprobaci√≥n (gate): el pipeline falla si existe cualquier test de datos fallido en los modelos obligatorios.
	‚Ä¢	(Opcional) Permitir advertencias no bloqueantes para pruebas marcadas como informativas, siempre que est√©n documentadas.
	‚Ä¢	Artefactos esperados: resultados de pruebas, resumen de calidad por modelo y actualizaci√≥n de metadatos (incluyendo lineage) visibles en Dataplex.  


## üì¶ Entregables
- Repositorio (GitHub/Bitbucket/GitLab) con todo los artefactos necesarios para la implementacion del ejercicio.

## üßÆ Criterios de Evaluaci√≥n

| Dimensi√≥n | Ponderaci√≥n | Descripci√≥n |
|------------|-------------|--------------|
| üß† **Calidad t√©cnica del c√≥digo (modularidad, pruebas, cobertura)** | **30%** | Revisi√≥n de c√≥digo del m√≥dulo `metadata_loader`. |
| üß± **Implementaci√≥n de modelos y pruebas en dbt** | **30%** | Estructura, tests y documentaci√≥n del proyecto `dbt`. |
| üóÉÔ∏è **Gobierno y trazabilidad (Dataplex o YAML)** | **25%** | Correcta representaci√≥n de metadatos, lineage y estados de calidad. |
| üîÅ **CI/CD y reproducibilidad** | **15%** | Pipelines funcionales, gates de validaci√≥n y reportes generados. |
